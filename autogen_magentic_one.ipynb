{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magentic-One\n",
    "\n",
    "Magentic-One は Microsoft Research が開発した汎用マルチエージェントシステムです。\n",
    "Magentic-One の Orchestrator エージェントは、計画を作成し、他のエージェントにタスクを委任し、目標に向けた進捗状況を追跡して、必要に応じて計画を動的に修正します。Orchestrator は、ファイルの読み取りと処理を行う FileSurfer エージェント、Web ブラウザーを操作する WebSurfer エージェント、またはコードの記述や実行を行う Coder エージェントまたは Computer Terminal エージェントにタスクを委任できます。\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"autogen-agentchat\"\n",
    "#!pip install \"autogen-ext[magentic-one,openai]\"\n",
    "#!playwright install --with-deps chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from autogen_ext.agents.magentic_one import MagenticOneCoderAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.conditions import ExternalTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient, AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination, TimeoutTermination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools の定義\n",
    "- search_website: Bing Search API を利用して Web検索を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def search_website(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform a Bing search for a given query and return the top snippets.\n",
    "\n",
    "    This function uses the Bing Search V7 API to send a search request with the provided query. It retrieves \n",
    "    the top three web page snippets from the search results. The search is performed in Japanese ('jp-JP').\n",
    "\n",
    "    :param query: The search query string to search for on the web.\n",
    "    :type query: str\n",
    "    :return: A list of the top three web page snippets, or an error message if the request fails.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    import os,re\n",
    "    import requests\n",
    "\n",
    "    # Add your Bing Search V7 subscription key and endpoint to your environment variables.\n",
    "    subscription_key = os.environ['BING_SEARCH_V7_SUBSCRIPTION_KEY']\n",
    "    endpoint = os.environ['BING_SEARCH_V7_ENDPOINT']\n",
    "\n",
    "    # Construct a request\n",
    "    mkt = 'jp-JP'\n",
    "    params = { 'q': query, 'mkt': mkt  ,\"textDecorations\": True, \"textFormat\": \"Raw\", \"count\": 3}\n",
    "    headers = { 'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "    # トレーススパンの作成\n",
    "    with tracer.start_as_current_span(\"search_website\") as span:\n",
    "        span.set_attribute(\"query\", query)  # クエリを記録\n",
    "\n",
    "        try:\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            jsonres = response.json()\n",
    "            snippets = [item['snippet'] for item in jsonres['webPages']['value']]\n",
    "\n",
    "            unicode_pattern = r\"\\\\u[0-9a-fA-F]{4}\"\n",
    "            cleaned_text = re.sub(unicode_pattern, \"\", str(snippets))\n",
    "            span.set_attribute(\"result\", cleaned_text)  # 結果を記録\n",
    "            return cleaned_text\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            error_message = \"Error: Request timed out\"\n",
    "            span.record_exception(Exception(error_message))  # 例外を記録\n",
    "            return error_message\n",
    "\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            error_message = \"Error: Failed to connect to the website\"\n",
    "            span.record_exception(Exception(error_message))\n",
    "            return error_message\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            error_message = f\"Error: HTTP {e.response.status_code} - {e.response.reason}\"\n",
    "            span.record_exception(e)\n",
    "            return error_message\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error: {str(e)}\"\n",
    "            span.record_exception(e)\n",
    "            return error_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エージェント定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"<Your_AzureOpenAI_deployment>\",\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=\"<Your_AzureOpenAI_key>\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint=\"<Your_AzureOpenAI_endpoint>\",\n",
    ")\n",
    "\n",
    "travel_agent = AssistantAgent(\n",
    "      \"travel_agent\",\n",
    "      description=\"あなたは総合トラベルエージェントです\",\n",
    "      model_client=client,\n",
    "    #tools=[search_website], #WebSurferを使用しない場合\n",
    "    reflect_on_tool_use=True,\n",
    "    system_message=\"\"\"あなたは優秀な総合トラベルエージェントです。\n",
    "    地方のトラベルエージェントが回答した情報をもとに、最終的な回答を作成します。\n",
    "    最終回答が完成したら調査結果を要約し、文の最後に TERMINATE を含めること!\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "surfer = MultimodalWebSurfer(\n",
    "    \"WebSurfer\",\n",
    "    model_client=client,\n",
    "    to_save_screenshots=True,\n",
    "    browser_data_dir=\"./browser_data\",\n",
    "    debug_dir=\"./debug\",\n",
    "    downloads_folder=\"./downloads\",\n",
    ")\n",
    "\n",
    "corder = MagenticOneCoderAgent(\n",
    "    \"Corder\",\n",
    "    model_client=client\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magentic-One の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination, TimeoutTermination\n",
    "# Define termination condition\n",
    "max_msg_termination = MaxMessageTermination(max_messages=10)\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "time_terminarion = TimeoutTermination(120)\n",
    "combined_termination = max_msg_termination | text_termination\n",
    "\n",
    "with tracer.start_as_current_span(\"magenticone\") as rollspan:\n",
    "\n",
    "    team = MagenticOneGroupChat([travel_agent, surfer], model_client=client, termination_condition=combined_termination, max_turns=10)\n",
    "\n",
    "    task = \"\"\"\n",
    "1週間のドバイ海外旅行で、おすすめの観光地とホテルを教えてください。\n",
    "\"\"\"\n",
    "    await Console(team.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 状態管理\n",
    "AutoGen では状態管理の仕組みが備わっています。エージェント、チーム、終了条件の状態を保存および読み込むことができます。多くの場合、これらのコンポーネントの状態をディスクに保存し、後で再度読み込むと便利です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state = await team.save_state()\n",
    "print(agent_state)\n",
    "\n",
    "import json\n",
    "with open(\"./magenticone_team_state.json\", \"w\") as f:\n",
    "    json.dump(agent_state, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態のロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"magenticone\") as rollspan:\n",
    "    ## load state from disk\n",
    "    with open(\"./magenticone_team_state.json\", \"r\") as f:\n",
    "        team_state = json.load(f)\n",
    "\n",
    "    new_agent_team = MagenticOneGroupChat([travel_agent, surfer], model_client=client, termination_condition=combined_termination, max_turns=10)\n",
    "\n",
    "    await new_agent_team.load_state(team_state)\n",
    "    stream = new_agent_team.run_stream(task=\"さっきのホテルって何て言ったっけ？\")\n",
    "    await Console(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
